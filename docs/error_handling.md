# Gestion des erreurs de traduction LLM

Ce document explique comment le syst√®me g√®re les √©checs de traduction par le LLM, notamment les erreurs de type "Mismatch in fragment count".

## üìã Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Syst√®me de retry automatique](#syst√®me-de-retry-automatique)
3. [Types d'erreurs g√©r√©es](#types-derreurs-g√©r√©es)
4. [Messages d'erreur d√©taill√©s](#messages-derreur-d√©taill√©s)
5. [Configuration](#configuration)
6. [D√©pannage](#d√©pannage)

## Vue d'ensemble

Le syst√®me de traduction inclut maintenant plusieurs m√©canismes pour g√©rer gracieusement les √©checs :

### ‚úÖ Am√©liorations impl√©ment√©es (Phase 1)

1. **Retry avec backoff exponentiel** : Les erreurs temporaires (timeout, rate limit) d√©clenchent automatiquement des nouvelles tentatives
2. **Validation pr√©-application** : Le nombre de fragments est v√©rifi√© avant d'appliquer les traductions
3. **Messages d'erreur contextuels** : Chaque erreur fournit des causes possibles et des solutions

## Syst√®me de retry automatique

### Fonctionnement

Le syst√®me effectue jusqu'√† **3 tentatives** (configurable) pour chaque requ√™te LLM qui √©choue avec :
- **Timeout** : D√©lai de `1s, 2s, 4s` (backoff exponentiel √ó2)
- **Rate Limit** : D√©lai de `1s, 3s, 9s` (backoff exponentiel √ó3)

### Configuration

Dans [llm.py](../src/ebook_translator/llm.py) :

```python
llm = LLM(
    model_name="deepseek-chat",
    url="https://api.deepseek.com",
    max_retries=3,       # Nombre de tentatives (d√©faut: 3)
    retry_delay=1.0,     # D√©lai initial en secondes (d√©faut: 1.0)
)
```

### Logs produits

```
‚è±Ô∏è Timeout API (tentative 1/3): Request timed out
‚è≥ Attente de 1.0s avant nouvelle tentative...
‚è±Ô∏è Timeout API (tentative 2/3): Request timed out
‚è≥ Attente de 2.0s avant nouvelle tentative...
‚úÖ Requ√™te LLM r√©ussie apr√®s 3 tentative(s) (1234 chars)
```

## Types d'erreurs g√©r√©es

### 1. Erreurs API temporaires (avec retry)

| Erreur | Retry | D√©lai | Description |
|--------|-------|-------|-------------|
| `APITimeoutError` | ‚úÖ Oui | √ó2 exponentiel | Le serveur n'a pas r√©pondu √† temps |
| `RateLimitError` | ‚úÖ Oui | √ó3 exponentiel | Trop de requ√™tes, limite de d√©bit atteinte |

### 2. Erreurs API permanentes (sans retry)

| Erreur | Retry | Description |
|--------|-------|-------------|
| `APIError` | ‚ùå Non | Erreur API g√©n√©rique (cl√© invalide, etc.) |
| `OpenAIError` | ‚ùå Non | Erreur client OpenAI |
| `Exception` | ‚ùå Non | Erreur inattendue |

### 3. Erreurs de validation

| Erreur | O√π | Description |
|--------|-----|-------------|
| Mismatch in fragment count | [replacement.py:82](../src/ebook_translator/htmlpage/replacement.py#L82) | Le LLM a retourn√© un nombre incorrect de fragments `</>` |
| Marqueur [=[END]=] manquant | [parser.py:50](../src/ebook_translator/translation/parser.py#L50) | La traduction est incompl√®te |
| Aucun segment trouv√© | [parser.py:81](../src/ebook_translator/translation/parser.py#L81) | Le format de sortie LLM est invalide |

## Messages d'erreur d√©taill√©s

### Exemple : Mismatch in fragment count

```
‚ùå Mismatch in fragment count:
  ‚Ä¢ Expected: 3 fragments
  ‚Ä¢ Got: 2 segments in translation

üìù Original fragments (3):
  "Hello", "beautiful", "world"

üîÑ Translation segments (2):
  "Bonjour", "monde magnifique"

üí° Causes possibles:
  ‚Ä¢ Le LLM a fusionn√© ou divis√© des fragments
  ‚Ä¢ Des s√©parateurs '</>' manquants ou en trop
  ‚Ä¢ Le contenu contient des '</>' dans le texte original

üîß Solutions:
  ‚Ä¢ V√©rifiez les logs LLM pour voir la r√©ponse brute
  ‚Ä¢ Relancez la traduction (retry automatique activ√©)
  ‚Ä¢ Ajustez le prompt pour mieux expliquer les s√©parateurs
```

### Exemple : Marqueur END manquant

```
‚ùå Traduction incompl√®te : le marqueur [=[END]=] est manquant.

üìù Aper√ßu de la sortie LLM:
<0/>Bonjour le monde
<1/>Ceci est un test...

üí° Causes possibles:
  ‚Ä¢ Le LLM a √©t√© interrompu avant la fin
  ‚Ä¢ La limite de tokens max_tokens est trop basse
  ‚Ä¢ Le LLM n'a pas suivi le format demand√©

üîß Solutions:
  ‚Ä¢ Augmentez max_tokens dans la config LLM
  ‚Ä¢ R√©duisez la taille des chunks √† traduire
  ‚Ä¢ V√©rifiez le prompt de traduction
```

## Configuration

### Param√®tres LLM recommand√©s

Pour √©viter les erreurs de traduction incompl√®te :

```python
llm = LLM(
    model_name="deepseek-chat",
    url="https://api.deepseek.com",
    temperature=0.85,
    max_retries=3,
    retry_delay=1.0,
)
llm.max_tokens = 4000  # Augmenter si les traductions sont tronqu√©es
```

### Param√®tres de traduction

```python
translator.translate(
    target_language=Language.FRENCH,
    output_epub=output_epub,
    max_concurrent=2,  # R√©duire si rate limit fr√©quent
    max_tokens=1500,   # Taille des chunks √† traduire
)
```

## D√©pannage

### Probl√®me : Rate limit fr√©quent

**Sympt√¥mes** :
```
üö¶ Limite de d√©bit atteinte (tentative 1/3)
```

**Solutions** :
1. R√©duire `max_concurrent` √† 1 dans `translator.translate()`
2. Augmenter `retry_delay` dans `LLM()` √† 2.0 ou 3.0 secondes
3. V√©rifier votre quota API sur la plateforme

### Probl√®me : Timeout syst√©matique

**Sympt√¥mes** :
```
‚è±Ô∏è Timeout API (tentative 3/3)
‚ùå √âchec d√©finitif apr√®s 3 tentatives
```

**Solutions** :
1. V√©rifier votre connexion internet
2. V√©rifier que l'URL de l'API est correcte
3. R√©duire la taille des chunks avec `max_tokens` plus petit
4. Augmenter `max_retries` √† 5

### Probl√®me : Mismatch de fragments

**Sympt√¥mes** :
```
‚ùå Mismatch in fragment count: expected 5, got 4
```

**Solutions** :
1. **V√©rifier les logs LLM** dans `logs/` pour voir la r√©ponse brute
2. **Ajuster le prompt** dans [template/translate.jinja](../template/translate.jinja) :
   ```jinja
   IMPORTANT : Tu DOIS conserver EXACTEMENT le m√™me nombre de balises '</>'
   que dans le texte original. Ne fusionne JAMAIS deux fragments.
   ```
3. **R√©duire la temp√©rature** du LLM (ex: `temperature=0.5`) pour des r√©ponses plus d√©terministes
4. **Essayer un autre mod√®le** si le probl√®me persiste

### Probl√®me : Traduction incompl√®te

**Sympt√¥mes** :
```
‚ùå Traduction incompl√®te : le marqueur [=[END]=] est manquant
```

**Solutions** :
1. **Augmenter `max_tokens`** dans `LLM()` :
   ```python
   llm.max_tokens = 8000  # Au lieu de 4000
   ```
2. **R√©duire la taille des chunks** dans `translator.translate()` :
   ```python
   max_tokens=1000  # Au lieu de 1500
   ```
3. **V√©rifier le prompt** pour s'assurer qu'il demande bien le marqueur `[=[END]=]`

## Logs et debugging

### Localisation des logs

Tous les logs LLM sont enregistr√©s dans `logs/` avec un horodatage :
```
logs/
  2025-10-20T15-30-51.880739.txt
  2025-10-20T15-32-27.693400.txt
  ...
```

### Contenu d'un log

```
=== LLM REQUEST LOG ===
Timestamp : 2025-10-20T15-30-51.880739
Model     : deepseek-chat
Prompt len: 1234 chars
----------------------------------------

--- PROMPT ---
Tu es un traducteur professionnel...

--- CONTENT ---
<0/>Hello world
<1/>This is a test

--- RESPONSE ---
<0/>Bonjour le monde
<1/>Ceci est un test
[=[END]=]
```

### Analyser les logs en cas d'erreur

1. **Ouvrir le dernier log** dans `logs/`
2. **V√©rifier la section RESPONSE** pour voir ce que le LLM a retourn√©
3. **Comparer avec le CONTENT** pour identifier les diff√©rences
4. **Compter les balises `</>`** pour d√©tecter un mismatch

## Tests

Des tests unitaires sont disponibles dans [tests/test_error_handling.py](../tests/test_error_handling.py) :

```bash
# Ex√©cuter les tests
poetry run pytest tests/test_error_handling.py -v

# Tests avec couverture
poetry run pytest tests/test_error_handling.py --cov=src/ebook_translator
```

## Prochaines am√©liorations (Phase 2)

Les am√©liorations suivantes sont pr√©vues mais non encore impl√©ment√©es :

- [ ] Strat√©gie de fallback configurable (garder l'original, marquer visuellement, etc.)
- [ ] Marqueurs visuels pour les zones non traduites
- [ ] Mode de reprise `--resume` pour relancer les chunks √©chou√©s
- [ ] Statistiques d√©taill√©es en fin de traduction
- [ ] Rapport HTML des zones probl√©matiques

## R√©f√©rences

- [llm.py](../src/ebook_translator/llm.py) : Syst√®me de retry
- [parser.py](../src/ebook_translator/translation/parser.py) : Validation de sortie LLM
- [replacement.py](../src/ebook_translator/htmlpage/replacement.py) : Validation des fragments
- [engine.py](../src/ebook_translator/translation/engine.py) : Application des traductions
- [worker.py](../src/ebook_translator/worker.py) : Gestion des erreurs parall√®les