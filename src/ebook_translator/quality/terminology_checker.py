"""
V√©rificateur de coh√©rence terminologique.

Ce module d√©tecte les incoh√©rences de traduction o√π le m√™me terme source
est traduit de diff√©rentes mani√®res dans le m√™me contexte.

Exemples :
- "Matrix" ‚Üí "Matrice" puis "Syst√®me"
- "Dr. Sakamoto" ‚Üí "Dr Sakamoto" puis "Docteur Sakamoto"
"""

import re
from dataclasses import dataclass, field
from typing import Optional
from collections import defaultdict


@dataclass
class TerminologyIssue:
    """
    Repr√©sente une incoh√©rence terminologique d√©tect√©e.

    Attributes:
        source_term: Le terme dans la langue source
        translations: Les diff√©rentes traductions trouv√©es
        positions: Positions o√π chaque traduction appara√Æt
        confidence: Niveau de confiance de l'incoh√©rence (0.0 √† 1.0)
        suggestion: Traduction recommand√©e (la plus fr√©quente)
    """
    source_term: str
    translations: list[str]
    positions: dict[str, list[int]] = field(default_factory=dict)
    confidence: float = 1.0
    suggestion: Optional[str] = None

    def __post_init__(self):
        """Calcule la suggestion (traduction la plus fr√©quente)."""
        if not self.suggestion and self.positions:
            # Compter les occurrences
            counts = {trans: len(pos) for trans, pos in self.positions.items()}
            # Prendre la plus fr√©quente
            self.suggestion = max(counts, key=counts.get)  # type: ignore

    def __str__(self) -> str:
        trans_list = "\n".join(
            f"    - \"{trans}\" ({len(pos)} fois)"
            for trans, pos in self.positions.items()
        )
        suggestion_str = f"\n  üí° Suggestion: utiliser \"{self.suggestion}\" partout" if self.suggestion else ""

        return (
            f"‚ö†Ô∏è Incoh√©rence terminologique d√©tect√©e:\n"
            f"  ‚Ä¢ Terme source: \"{self.source_term}\"\n"
            f"  ‚Ä¢ Traductions trouv√©es:\n{trans_list}"
            f"{suggestion_str}"
        )


class TerminologyChecker:
    """
    V√©rificateur de coh√©rence terminologique.

    Suit les traductions de termes sp√©cifiques (noms propres, termes techniques)
    et d√©tecte les incoh√©rences.

    Example:
        >>> checker = TerminologyChecker()
        >>> checker.add_pair("Matrix", "Matrice", position=0)
        >>> checker.add_pair("Matrix", "Syst√®me", position=10)
        >>> issues = checker.get_issues()
        >>> for issue in issues:
        ...     print(issue)
    """

    def __init__(self, min_occurrences: int = 2):
        """
        Initialise le v√©rificateur.

        Args:
            min_occurrences: Nombre minimum d'occurrences pour signaler une incoh√©rence
        """
        self.min_occurrences = min_occurrences
        # {terme_source: {traduction: [positions]}}
        self._translations: dict[str, dict[str, list[int]]] = defaultdict(
            lambda: defaultdict(list)
        )

    def add_pair(
        self,
        source_term: str,
        translated_term: str,
        position: Optional[int] = None,
    ) -> None:
        """
        Enregistre une paire source ‚Üí traduction.

        Args:
            source_term: Terme dans la langue source
            translated_term: Traduction
            position: Position dans le document (optionnel)
        """
        # Normaliser les termes pour comparaison
        source_normalized = self._normalize_term(source_term)
        trans_normalized = self._normalize_term(translated_term)

        # Ignorer si identiques (noms propres non traduits, etc.)
        if source_normalized == trans_normalized:
            return

        # Enregistrer la traduction
        pos = position if position is not None else len(
            self._translations[source_normalized]
        )
        self._translations[source_normalized][trans_normalized].append(pos)

    def get_issues(self, min_confidence: float = 0.7) -> list[TerminologyIssue]:
        """
        R√©cup√®re toutes les incoh√©rences d√©tect√©es.

        Args:
            min_confidence: Seuil de confiance minimum

        Returns:
            Liste des incoh√©rences terminologiques
        """
        issues: list[TerminologyIssue] = []

        for source_term, translations in self._translations.items():
            # Besoin d'au moins 2 traductions diff√©rentes
            if len(translations) < 2:
                continue

            # V√©rifier le nombre total d'occurrences
            total_occurrences = sum(len(positions) for positions in translations.values())
            if total_occurrences < self.min_occurrences:
                continue

            # Calculer la confiance de l'incoh√©rence
            # Plus il y a de traductions diff√©rentes, plus on est confiant qu'il y a un probl√®me
            confidence = self._calculate_inconsistency_confidence(translations)

            if confidence >= min_confidence:
                issues.append(TerminologyIssue(
                    source_term=source_term,
                    translations=list(translations.keys()),
                    positions=dict(translations),
                    confidence=confidence,
                ))

        return sorted(issues, key=lambda x: x.confidence, reverse=True)

    def extract_terms_from_pair(
        self,
        source_text: str,
        translated_text: str,
        position: Optional[int] = None,
    ) -> None:
        """
        Extrait et enregistre automatiquement les termes d'une paire source/traduction.

        D√©tecte :
        - Noms propres (commen√ßant par une majuscule)
        - Termes techniques (mots avec majuscules internes: "Matrix", "API", etc.)
        - Noms de lieux, personnages, etc.

        Args:
            source_text: Texte source
            translated_text: Texte traduit
            position: Position dans le document
        """
        # Extraire noms propres du texte source
        source_terms = self._extract_proper_nouns(source_text)
        translated_terms = self._extract_proper_nouns(translated_text)

        # Tenter de matcher les termes source ‚Üí traduction
        # Strat√©gie simple : m√™me ordre d'apparition
        for i, source_term in enumerate(source_terms):
            if i < len(translated_terms):
                self.add_pair(source_term, translated_terms[i], position)

    def _extract_proper_nouns(self, text: str) -> list[str]:
        """
        Extrait les noms propres d'un texte.

        D√©tecte :
        - Mots commen√ßant par une majuscule (sauf d√©but de phrase)
        - S√©quences de mots capitalis√©s (ex: "Dr. Sakamoto")
        - Acronymes (ex: "NASA", "API")

        Args:
            text: Le texte √† analyser

        Returns:
            Liste de noms propres
        """
        proper_nouns = []

        # Pattern pour noms propres: majuscule + minuscules (ou tout en majuscules pour acronymes)
        # Mais pas au d√©but de phrase
        pattern = r'(?<!\.\s)(?<!\n)(?<!\A)\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*|[A-Z]{2,})\b'

        matches = re.finditer(pattern, text)
        for match in matches:
            noun = match.group(1).strip()
            # Filtrer les mots courants qui commencent souvent les phrases
            if noun.lower() not in {'the', 'a', 'an', 'this', 'that', 'these', 'those', 'i'}:
                proper_nouns.append(noun)

        return proper_nouns

    def _normalize_term(self, term: str) -> str:
        """
        Normalise un terme pour comparaison.

        Args:
            term: Le terme √† normaliser

        Returns:
            Terme normalis√©
        """
        # Supprimer espaces multiples et trim
        normalized = ' '.join(term.split())
        return normalized

    def _calculate_inconsistency_confidence(
        self,
        translations: dict[str, list[int]],
    ) -> float:
        """
        Calcule la confiance qu'il y a une incoh√©rence.

        Plus il y a de traductions diff√©rentes ET plus elles sont √©quilibr√©es,
        plus on est confiant qu'il y a un probl√®me.

        Args:
            translations: Dictionnaire {traduction: [positions]}

        Returns:
            Confiance entre 0.0 et 1.0
        """
        num_translations = len(translations)
        if num_translations < 2:
            return 0.0

        # Compter les occurrences
        counts = [len(positions) for positions in translations.values()]
        total = sum(counts)

        # Si une traduction domine √† >80%, moins confiant (peut √™tre l√©gitime)
        max_count = max(counts)
        dominant_ratio = max_count / total

        if dominant_ratio > 0.8:
            # Moins confiant, mais toujours signaler
            return 0.7

        # Sinon, confiance √©lev√©e
        # Plus il y a de traductions diff√©rentes, plus c'est suspect
        return min(0.7 + (num_translations - 2) * 0.1, 1.0)

    def get_glossary(self) -> dict[str, str]:
        """
        G√©n√®re un glossaire des traductions recommand√©es.

        Retourne un dictionnaire {terme_source: traduction_recommand√©e}
        bas√© sur la traduction la plus fr√©quente.

        Returns:
            Dictionnaire de glossaire
        """
        glossary: dict[str, str] = {}

        for source_term, translations in self._translations.items():
            if not translations:
                continue

            # Trouver la traduction la plus fr√©quente
            counts = {trans: len(pos) for trans, pos in translations.items()}
            most_frequent = max(counts, key=counts.get)  # type: ignore

            glossary[source_term] = most_frequent

        return glossary

    def clear(self) -> None:
        """Efface toutes les donn√©es enregistr√©es."""
        self._translations.clear()
