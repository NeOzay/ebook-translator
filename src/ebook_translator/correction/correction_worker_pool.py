"""
Pool de CorrectionWorkers pour traiter les erreurs de traduction en parall√®le.

Ce module fournit un pool de N workers qui consomment la ErrorQueue en parall√®le,
permettant d'acc√©l√©rer significativement le traitement des erreurs de traduction.
"""

import threading
from typing import TYPE_CHECKING, Optional

from ..logger import get_logger
from .correction_worker import CorrectionWorker

if TYPE_CHECKING:
    from ..llm import LLM
    from ..store import Store
    from .error_queue import ErrorQueue

logger = get_logger(__name__)


class CorrectionWorkerPool:
    """
    Pool de CorrectionWorkers pour traiter les erreurs en parall√®le.

    Ce pool g√®re N instances de CorrectionWorker qui consomment tous la m√™me
    ErrorQueue de mani√®re thread-safe. Chaque worker traite les erreurs
    ind√©pendamment, permettant un traitement parall√®le des corrections LLM.

    Avantages :
    - Performance : Les appels LLM (I/O-bound) se font en parall√®le
    - Scalabilit√© : Configurable via num_workers
    - Thread-safety : ErrorQueue garantit FIFO thread-safe
    - Statistiques agr√©g√©es : Combine les stats de tous les workers

    Attributes:
        error_queue: Queue partag√©e par tous les workers
        llm: Instance LLM pour les corrections
        num_workers: Nombre de workers dans le pool
        workers: Liste des instances CorrectionWorker
        target_language: Langue cible de la traduction

    Example:
        >>> pool = CorrectionWorkerPool(
        ...     error_queue=error_queue,
        ...     llm=llm,
        ...     store=store,
        ...     target_language="fr",
        ...     num_workers=3,
        ... )
        >>> pool.start()
        >>> # ... traductions en cours ...
        >>> pool.stop(timeout=30.0)
        >>> stats = pool.get_aggregated_statistics()
        >>> print(f"Corrected: {stats['corrected']}, Failed: {stats['failed']}")
    """

    def __init__(
        self,
        error_queue: "ErrorQueue",
        llm: "LLM",
        store: "Store",
        target_language: str,
        num_workers: int = 2,
    ):
        """
        Initialise le pool de CorrectionWorkers.

        Args:
            error_queue: Queue partag√©e contenant les erreurs √† corriger
            llm: Instance LLM pour les corrections
            store: Store pour sauvegarder les corrections
            target_language: Code de la langue cible (ex: "fr", "en")
            num_workers: Nombre de workers dans le pool (d√©faut: 2)

        Raises:
            ValueError: Si num_workers < 1
        """
        if num_workers < 1:
            raise ValueError(f"num_workers doit √™tre >= 1, re√ßu: {num_workers}")

        self.error_queue = error_queue
        self.llm = llm
        self.num_workers = num_workers
        self.target_language = target_language

        # Cr√©er les workers
        self.workers: list[CorrectionWorker] = []
        for worker_id in range(num_workers):
            worker = CorrectionWorker(
                error_queue=error_queue,
                llm=llm,
                store=store,
                target_language=target_language,
                worker_id=worker_id,  # Pour identification dans les logs
            )
            self.workers.append(worker)

        logger.info(
            f"üîß CorrectionWorkerPool cr√©√© avec {num_workers} worker(s)"
        )

    def start(self) -> None:
        """
        D√©marre tous les workers du pool en parall√®le.

        Chaque worker tourne dans son propre thread daemon et consomme
        la ErrorQueue de mani√®re thread-safe (FIFO).

        Example:
            >>> pool.start()
            üîß D√©marrage de 3 CorrectionWorkers...
            üîß [Worker-0] D√©marrage du thread de correction
            üîß [Worker-1] D√©marrage du thread de correction
            üîß [Worker-2] D√©marrage du thread de correction
            ‚úÖ 3 CorrectionWorkers d√©marr√©s
        """
        logger.info(f"üîß D√©marrage de {self.num_workers} CorrectionWorker(s)...")

        for worker in self.workers:
            worker.start()

        logger.info(f"‚úÖ {self.num_workers} CorrectionWorker(s) d√©marr√©(s)")

    def stop(self, timeout: float = 10.0) -> bool:
        """
        Arr√™te tous les workers du pool proprement.

        Envoie un signal d'arr√™t √† tous les workers et attend qu'ils
        terminent dans le d√©lai sp√©cifi√©. Si un worker ne s'arr√™te pas
        dans le d√©lai, log un warning et continue (le worker est daemon).

        Args:
            timeout: Temps d'attente maximum par worker en secondes (d√©faut: 10.0)

        Returns:
            True si tous les workers se sont arr√™t√©s dans le d√©lai, False sinon

        Example:
            >>> pool.stop(timeout=30.0)
            üõë Arr√™t de 3 CorrectionWorker(s)...
            ‚úÖ 3/3 CorrectionWorker(s) arr√™t√©(s)
            True
        """
        logger.info(f"üõë Arr√™t de {self.num_workers} CorrectionWorker(s)...")

        all_stopped = True
        stopped_count = 0

        for worker in self.workers:
            success = worker.stop(timeout=timeout)
            if success:
                stopped_count += 1
            else:
                all_stopped = False
                logger.warning(
                    f"‚ö†Ô∏è [Worker-{worker.worker_id}] n'a pas pu s'arr√™ter dans le d√©lai ({timeout}s)"
                )

        if all_stopped:
            logger.info(f"‚úÖ {stopped_count}/{self.num_workers} CorrectionWorker(s) arr√™t√©(s)")
        else:
            logger.warning(
                f"‚ö†Ô∏è {stopped_count}/{self.num_workers} CorrectionWorker(s) arr√™t√©(s) "
                f"({self.num_workers - stopped_count} timeout)"
            )

        return all_stopped

    def switch_all_stores(self, new_store: "Store") -> None:
        """
        Bascule tous les workers vers un nouveau store (ex: Phase 1 ‚Üí Phase 2).

        Cette m√©thode est utilis√©e lors de la transition entre phases du pipeline
        pour que tous les workers sauvegardent leurs corrections dans le bon store.

        Args:
            new_store: Le nouveau store √† utiliser

        Example:
            >>> # Transition Phase 1 ‚Üí Phase 2
            >>> pool.switch_all_stores(multi_store.refined_store)
            üîÑ Basculement de 3 worker(s) vers nouveau store...
            ‚úÖ 3 worker(s) bascul√©(s)
        """
        logger.info(
            f"üîÑ Basculement de {self.num_workers} worker(s) vers nouveau store..."
        )

        for worker in self.workers:
            worker.switch_store(new_store)

        logger.info(f"‚úÖ {self.num_workers} worker(s) bascul√©(s)")

    def get_aggregated_statistics(self) -> dict:
        """
        Agr√®ge les statistiques de tous les workers du pool.

        Combine les compteurs corrected_count et failed_count de chaque worker
        pour obtenir les statistiques globales du pool.

        Returns:
            Dictionnaire avec statistiques agr√©g√©es :
            {
                "corrected": int,      # Total erreurs corrig√©es
                "failed": int,         # Total erreurs √©chou√©es
                "is_alive": bool,      # True si au moins un worker est actif
                "workers_alive": int,  # Nombre de workers actifs
                "by_worker": [...]     # Stats d√©taill√©es par worker
            }

        Example:
            >>> stats = pool.get_aggregated_statistics()
            >>> print(f"Total corrections: {stats['corrected']}")
            >>> print(f"Workers actifs: {stats['workers_alive']}/{len(pool.workers)}")
        """
        total_corrected = 0
        total_failed = 0
        workers_alive = 0
        by_worker = []

        for worker in self.workers:
            worker_stats = worker.get_statistics()
            total_corrected += worker_stats["corrected"]
            total_failed += worker_stats["failed"]

            if worker_stats["is_alive"]:
                workers_alive += 1

            by_worker.append({
                "worker_id": worker.worker_id,
                "corrected": worker_stats["corrected"],
                "failed": worker_stats["failed"],
                "is_alive": worker_stats["is_alive"],
            })

        return {
            "corrected": total_corrected,
            "failed": total_failed,
            "is_alive": workers_alive > 0,
            "workers_alive": workers_alive,
            "total_workers": self.num_workers,
            "by_worker": by_worker,
        }

    def __repr__(self) -> str:
        """Repr√©sentation pour le debug."""
        stats = self.get_aggregated_statistics()
        return (
            f"CorrectionWorkerPool(\n"
            f"  num_workers={self.num_workers},\n"
            f"  corrected={stats['corrected']},\n"
            f"  failed={stats['failed']},\n"
            f"  workers_alive={stats['workers_alive']}/{self.num_workers}\n"
            f")"
        )
